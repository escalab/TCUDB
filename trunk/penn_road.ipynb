{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GLep5OONa57k",
    "outputId": "4aaa51bf-b7d6-4c71-e416-63d8f79f8729",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-28 18:23:24--  https://snap.stanford.edu/data/roadNet-PA.txt.gz\n",
      "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
      "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9945340 (9.5M) [application/x-gzip]\n",
      "Saving to: ‘roadNet-PA.txt.gz’\n",
      "\n",
      "roadNet-PA.txt.gz   100%[===================>]   9.48M  3.50MB/s    in 2.7s    \n",
      "\n",
      "2020-10-28 18:23:27 (3.50 MB/s) - ‘roadNet-PA.txt.gz’ saved [9945340/9945340]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !wget https://snap.stanford.edu/data/roadNet-PA.txt.gz\n",
    "# !gzip -d roadNet-PA.txt.gz\n",
    "# !head -n10 roadNet-PA.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wx-Bttnlo0jX"
   },
   "source": [
    "## Read edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QV5EYReLjDgw",
    "outputId": "38a7b358-a1a1-46a3-c641-69d221353af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw data has #edges: 3083796\n",
      "raw data has #nodes: 1090919\n"
     ]
    }
   ],
   "source": [
    "num_nodes = 1090920\n",
    "num_edges = 3083796\n",
    "# change k to generate different size of table\n",
    "input_k = 32768\n",
    "\n",
    "edges = []\n",
    "for line in open('roadNet-PA.txt'):\n",
    "    if line[0] != '#':\n",
    "        u, v = line.strip().split('\\t')\n",
    "        u = int(u)\n",
    "        v = int(v)\n",
    "        edges.append((u, v))\n",
    "\n",
    "print(\"raw data has #edges: {}\".format(len(edges)))\n",
    "print(\"raw data has #nodes: {}\".format(max([max(u, v) for u, v in edges])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBj08sDUo7CW"
   },
   "source": [
    "## Find the largest connected component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2-RNppXdk74d",
    "outputId": "efda6c3a-41be-42d2-df40-d2be4185046f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1087562\n"
     ]
    }
   ],
   "source": [
    "from collections import deque, Counter\n",
    "\n",
    "def largest_wcc(num_nodes, edges):\n",
    "    visited = [-1 for _ in range(num_nodes)]\n",
    "    neighbors = [[] for _ in range(num_nodes)]\n",
    "    for u, v in edges:\n",
    "        neighbors[u].append(v)\n",
    "        neighbors[v].append(u)\n",
    "\n",
    "    # BFS\n",
    "    num_wcc = 0\n",
    "    for start in range(num_nodes):\n",
    "        if visited[start] >= 0:\n",
    "            continue\n",
    "\n",
    "        visited[start] = num_wcc\n",
    "        queue = deque([start])\n",
    "        while len(queue) > 0:\n",
    "            u = queue.popleft()\n",
    "            for v in neighbors[u]:\n",
    "                if visited[v] < 0:\n",
    "                    visited[v] = num_wcc\n",
    "                    queue.append(v)\n",
    "        num_wcc += 1\n",
    "  \n",
    "    wcc, size = Counter(visited).most_common(1)[0]\n",
    "    print(wcc, size)\n",
    "    return [i for i in range(num_nodes) if visited[i] == wcc]\n",
    "\n",
    "# selected_nodes contain the node indices of the connected component\n",
    "selected_nodes = largest_wcc(num_nodes, edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72WwQrjUpJgY"
   },
   "source": [
    "## Shrink the graph by randomly merging the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NnH4h5NpjjuU",
    "outputId": "28eabab9-e6e9-48b5-9ee5-7c103a34ea11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After shrinking, #nodes: 32768\t#edges: 82070\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def get_parent(parent, node):\n",
    "    visited = [node]\n",
    "    while parent[node] != node:\n",
    "        node = parent[node]\n",
    "        visited.append(node)\n",
    "\n",
    "    for n in visited:\n",
    "        parent[n] = node\n",
    "    return node\n",
    "\n",
    "\n",
    "def random_shrink(N, selected_nodes, edges, new_N=2048):\n",
    "    \"\"\"Randomly shrink a graph.\n",
    "\n",
    "    Args:\n",
    "      N (int): the number of nodes in the graph\n",
    "      selected_nodes (List of int): the connected component that we want to shrink\n",
    "      edges (List of tuple): the edges of the graph\n",
    "      new_N (int): the number of nodes that we want to keep\n",
    "\n",
    "    Returns:\n",
    "      List of int: the node indices after shrinking\n",
    "      List of tuple: the remaining edges after shrinking\n",
    "    \"\"\"\n",
    "    parent = list(range(N))\n",
    "\n",
    "    current_N = len(selected_nodes)\n",
    "    selected_nodes_set = set(selected_nodes)\n",
    "    random.shuffle(edges)\n",
    "\n",
    "    for u, v in edges:\n",
    "        if u not in selected_nodes_set or \\\n",
    "           v not in selected_nodes_set:\n",
    "            continue\n",
    "        u_parent = get_parent(parent, u)\n",
    "        v_parent = get_parent(parent, v)\n",
    "        if u_parent != v_parent:\n",
    "            parent[u_parent] = v_parent\n",
    "            current_N -= 1\n",
    "        if current_N <= new_N:\n",
    "            break\n",
    "\n",
    "    new_nodes = set([])\n",
    "    for n in selected_nodes:\n",
    "        new_nodes.add(get_parent(parent, n))\n",
    "    new_nodes = set(new_nodes)\n",
    "\n",
    "    new_edges = []\n",
    "    for u, v in edges:\n",
    "        if u not in selected_nodes_set or \\\n",
    "           v not in selected_nodes_set:\n",
    "            continue\n",
    "\n",
    "        u_parent = parent[u]\n",
    "        v_parent = parent[v]\n",
    "        if u_parent < v_parent:\n",
    "            new_edges.append((u_parent, v_parent))\n",
    "        elif u_parent > v_parent:\n",
    "            new_edges.append((v_parent, u_parent))\n",
    "    \n",
    "    return new_nodes, new_edges\n",
    "\n",
    "# new_nodes, new_edges = random_shrink(num_nodes, selected_nodes, edges, new_N=1024)\n",
    "new_nodes, new_edges = random_shrink(num_nodes, selected_nodes, edges, input_k)\n",
    "\n",
    "print(\"After shrinking, #nodes: {}\\t#edges: {}\".format(len(new_nodes), len(new_edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the shrinked network for node id and edges\n",
    "def reorder_network(new_nodes, new_edges):\n",
    "    map_dict = {} # mapping of node indices after reordering\n",
    "    new_edges_reordered = []\n",
    "    \n",
    "    for counter, val in enumerate(set(new_nodes)):\n",
    "        map_dict[val] = counter\n",
    "        \n",
    "    temp = {i: j for j, i in enumerate(set(new_nodes))} \n",
    "    new_nodes_reordered = [temp[i] for i in new_nodes]\n",
    "    \n",
    "    # reorder edges from map_dict\n",
    "    for t in new_edges:\n",
    "        lst = list(t) # tuple is immutable\n",
    "        lst[0], lst[1] = map_dict[lst[0]], map_dict[lst[1]]\n",
    "        new_edges_reordered.append(tuple(lst))\n",
    "    return new_nodes_reordered, new_edges_reordered\n",
    "\n",
    "def computeOutdegree(edges):\n",
    "    outdegree = {}\n",
    "    \n",
    "    for t in edges:\n",
    "        outdegree[t[0]] = outdegree[t[0]]+1 if (t[0] in outdegree) else 1\n",
    "        \n",
    "    return outdegree\n",
    "\n",
    "def createNodeTable(nodes, k):\n",
    "    output_node_table = \"node_\"+str(k)+\".tbl\"\n",
    "    \n",
    "    with open(output_node_table, 'w') as f:\n",
    "        for n in nodes:\n",
    "            f.write(str(n)+'|'+'\\n')\n",
    "    f.close()\n",
    "    print(\"Finished generating node_{}.tbl\".format(k))\n",
    "\n",
    "def createEdgeTable(edges, k):\n",
    "    output_edge_table = \"edge_\"+str(k)+\".tbl\"\n",
    "    \n",
    "    with open(output_edge_table, 'w') as f:\n",
    "        for t in edges:\n",
    "            f.write(str(t[0])+'|'+str(t[1])+'|'+str(1)+'|'+'\\n')\n",
    "                \n",
    "        f.close()\n",
    "        print(\"Finished generating edge_{}.tbl\".format(k))\n",
    "        \n",
    "def createOutdegreeTable(nodes, edges, k):\n",
    "    output_outdegree_table = \"outdegree_\"+str(k)+\".tbl\"\n",
    "    # calculate outdegree due to our design schema in edge table\n",
    "    outdegree = computeOutdegree(edges)\n",
    "    \n",
    "    with open(output_outdegree_table, 'w') as f:\n",
    "        for n in nodes:\n",
    "            # FIXME: all outdegree init to 1 to avoid divide by 0 when executing query\n",
    "            degree = outdegree[n]+1 if (n in outdegree) else 1\n",
    "            f.write(str(n)+'|'+str(degree)+'|'+'\\n')\n",
    "        f.close()\n",
    "        print(\"Finished generating outdegree_{}.tbl\".format(k))\n",
    "\n",
    "def createPagerankTable(node_tbl, outdegree_tbl, k, alpha=0.85):\n",
    "    output_pagerank_table = \"pagerank_\"+str(k)+\".tbl\"\n",
    "    \n",
    "    import re\n",
    "    node_dict = {}\n",
    "    with open(node_tbl) as f:\n",
    "        for line in f:\n",
    "            n = int(re.search(r'\\d+', line).group(0))\n",
    "            if n not in node_dict:\n",
    "                node_dict[n] = 0\n",
    "                \n",
    "    initVal = (1-alpha)/len(node_dict)\n",
    "    output = open(output_pagerank_table, 'w')\n",
    "    with open(outdegree_tbl) as f:\n",
    "        for line in f:\n",
    "            id_, degree = re.findall(r'\\d+', line)\n",
    "            if int(id_) in node_dict:\n",
    "                output.write(id_+'|'+\"{:.9f}\".format(initVal)+'|'+'\\n')\n",
    "        output.close()\n",
    "        f.close()\n",
    "    print(\"Finished generating pagerank_{}.tbl\".format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K is 32768\n",
      "Finished generating node_32768.tbl\n",
      "Finished generating edge_32768.tbl\n",
      "Finished generating outdegree_32768.tbl\n",
      "Finished generating pagerank_32768.tbl\n"
     ]
    }
   ],
   "source": [
    "nodes_, edges_ = reorder_network(new_nodes, new_edges)\n",
    "k = input_k\n",
    "print(\"K is {}\".format(k))\n",
    "createNodeTable(nodes_, k)\n",
    "createEdgeTable(edges_, k)\n",
    "createOutdegreeTable(nodes_, edges_, k)\n",
    "# must create node table and outdegree table first\n",
    "createPagerankTable('node_'+ str(k) +'.tbl', 'outdegree_'+ str(k) +'.tbl',k)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "「penn_road.ipynb」的副本",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
